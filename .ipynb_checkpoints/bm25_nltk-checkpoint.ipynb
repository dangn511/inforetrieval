{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1942c4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\edge\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3beb7f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rank_bm25\n",
      "  Downloading rank_bm25-0.2.1-py3-none-any.whl (8.5 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\edge\\appdata\\roaming\\python\\python37\\site-packages (from rank_bm25) (1.21.1)\n",
      "Installing collected packages: rank-bm25\n",
      "Successfully installed rank-bm25-0.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1.1; however, version 21.2.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\edge\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4424f00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import pickle, json\n",
    "import pandas as pd\n",
    "\n",
    "from rank_bm25 import *\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b8e76927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_remove(lst):\n",
    "    lst1=list()\n",
    "    for str in lst:\n",
    "        text_tokens = word_tokenize(str)\n",
    "        tokens_without_sw = [word for word in text_tokens if not word in all_stopwords_gensim]\n",
    "        str_t = \" \".join(tokens_without_sw)\n",
    "        lst1.append(str_t)\n",
    " \n",
    "    return lst1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1524cc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spl_chars_removal(lst):\n",
    "    lst1=list()\n",
    "    for element in lst:\n",
    "        str= \"\"\n",
    "        str = re.sub(\"[^A-Za-z0-9]+\",\" \",element)\n",
    "        lst1.append(str)\n",
    "    return lst1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4720876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(sentence):\n",
    "    temp_str = sentence.encode('ascii', errors='ignore').decode(\"utf-8\")\n",
    "    result = \" \".join(temp_str.split())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e3a666b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "charl\n",
      "iv,\n",
      "king\n",
      "of\n",
      "bohemia\n",
      "and\n",
      "holi\n",
      "roman\n",
      "emperor,\n",
      "had\n",
      "a\n",
      "long\n",
      "and\n",
      "success\n",
      "reign.\n",
      "the\n",
      "empir\n",
      "he\n",
      "rule\n",
      "from\n",
      "pragu\n",
      "expanded,\n",
      "and\n",
      "hi\n",
      "subject\n",
      "live\n",
      "in\n",
      "peac\n",
      "and\n",
      "prosperity.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer() \n",
    "sentence = \"Charles IV, King of Bohemia and Holy Roman Emperor, had a long and successful reign. The Empire he ruled from Prague expanded, and his subjects lived in peace and prosperity.\"\n",
    "for word in sentence.split():\n",
    "    print(ps.stem(word))\n",
    "    \n",
    "def sentence_stemmer(sentence):\n",
    "    return [ps.stem(word) for word in sentence]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "62a969f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7426\n",
      "['job', 'descript', 'the', 'success', 'candid', 'attach', 'branch', 'offic', 'perform', 'follow', 'duti', 'administr', 'assistant ', 'describ', 'duties ', 'provid', 'gener', 'administr', 'support', 'office ', 'data', 'entri', 'file', 'document', ' hardcopi', 'electronic ', 'prepar', 'invoices ', 'correspond', 'support', 'documents ', 'handl', 'daili', 'routin', 'invoic', 'relat', 'duties ', 'commun', 'custom', 'work', 'partners ', 'undertak', 'duti', 'assign', 'superior', 'time', 'time ', 'e', 'xpectations ', 'meticul', 'abl', 'multi task', 'profici', 'ms', 'offic', 'skill', 'basic', 'use', 'sap', 'system ', ' don t', 'worri', 'guid', 'you ', 'possess', 'good', 'interperson', 'commun', 'skill', ' we', 'need', 'happi', 'people ', 'exhibit', 'good', 'work', 'attitud', 'team ori', 'spirit', 'career', 'level ', 'junior', 'execut', 'qualification ', 'profession', 'certificate nitec ', 'diploma ', 'advanced higher gradu', 'diploma', 'year', 'experience ', '1 2', 'year', 'job', 'type ', 'full time ', '5', 'day', 'work', 'week ', 'job', 'specializations ', 'admin human', 'resourc', ' ', 'clerical administr', 'support']\n",
      "saved\n"
     ]
    }
   ],
   "source": [
    "with open('cleaned_jd_3.json', 'r') as fp:\n",
    "    master_list = json.load(fp)\n",
    "    \n",
    "job_desc_docs = []\n",
    "for i in master_list:\n",
    "    job_desc_docs.append(master_list[i]['job_description'])\n",
    "\n",
    "print(len(job_desc_docs))\n",
    "job_desc_docs_raw = job_desc_docs\n",
    "\n",
    "job_desc_docs = [remove_stopwords(i).split() for i in job_desc_docs]\n",
    "job_desc_docs = [spl_chars_removal(i) for i in job_desc_docs]\n",
    "job_desc_docs_stemmed = [sentence_stemmer(i) for i in job_desc_docs]\n",
    "print(job_desc_docs_stemmed[1])\n",
    "\n",
    "with open('job_desc_tokenized.pickle', 'wb') as handle:\n",
    "    pickle.dump(job_desc_docs_stemmed, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "022b89f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "962\n",
      "['skill', ' ', 'program', 'languages ', 'python', ' pandas ', 'numpy ', 'scipy ', 'scikit learn ', 'matplotlib ', 'sql ', 'java ', 'javascript jquery ', ' ', 'machin', 'learning ', 'regression ', 'svm ', 'nave', 'bayes ', 'knn ', 'random', 'forest ', 'decis', 'trees ', 'boost', 'techniques ', 'cluster', 'analysis ', 'word', 'embedding ', 'sentiment', 'analysis ', 'natur', 'languag', 'processing ', 'dimension', 'reduction ', 'topic', 'model', ' lda ', 'nmf ', 'pca', ' ', 'neural', 'nets ', ' ', 'databas', 'visualizations ', 'mysql ', 'sqlserver ', 'cassandra ', 'hbase ', 'elasticsearch', 'd3 js ', 'dc js ', 'plotly ', 'kibana ', 'matplotlib ', 'ggplot ', 'tableau ', ' ', 'others ', 'regular', 'expression ', 'html ', 'css ', 'angular', '6 ', 'logstash ', 'kafka ', 'python', 'flask ', 'git ', 'docker ', 'vision', ' ', 'open', 'cv', 'understand', 'deep', 'learning educ', 'detail', 'data', 'scienc', 'assur', 'associ', 'data', 'scienc', 'assur', 'associ', ' ', 'ernst', ' ', 'young', 'llp', 'skill', 'detail', 'javascript ', 'exprienc', ' ', '24', 'month', 'jquery ', 'exprienc', ' ', '24', 'month', 'python ', 'exprienc', ' ', '24', 'monthscompani', 'detail', 'compani', ' ', 'ernst', ' ', 'young', 'llp', 'descript', ' ', 'fraud', 'investig', 'disput', 'servic', 'assur', 'technolog', 'assist', 'review', 'tar', ' technolog', 'assist', 'review ', 'assist', 'acceler', 'review', 'process', 'run', 'analyt', 'gener', 'reports ', ' ', 'core', 'member', 'team', 'help', 'develop', 'autom', 'review', 'platform', 'tool', 'scratch', 'assist', 'e', 'discoveri', 'domain ', 'tool', 'implement', 'predict', 'code', 'topic', 'model', 'autom', 'reviews ', 'result', 'reduc', 'labor', 'cost', 'time', 'spent', 'lawyer', 'review ', ' ', 'understand', 'end', 'end', 'flow', 'solution ', 'research', 'develop', 'classif', 'models ', 'predict', 'analysi', 'mine', 'inform', 'present', 'text', 'data ', 'work', 'analyz', 'output', 'precis', 'monitor', 'entir', 'tool ', ' ', 'tar', 'assist', 'predict', 'coding ', 'topic', 'model', 'evid', 'follow', 'ey', 'standards ', 'develop', 'classifi', 'model', 'order', 'identifi', ' red', 'flags ', 'fraud rel', 'issues ', 'tool', ' ', 'technologies ', 'python ', 'scikit learn ', 'tfidf ', 'word2vec ', 'doc2vec ', 'cosin', 'similarity ', 'nave', 'bayes ', 'lda ', 'nmf', 'topic', 'modelling ', 'vader', 'text', 'blob', 'sentiment', 'analysis ', 'matplot', 'lib ', 'tableau', 'dashboard', 'reporting ', 'multipl', 'data', 'scienc', 'and', 'analyt', 'project', ' usa', 'clients ', 'text', 'analyt', ' ', 'motor', 'vehicl', 'custom', 'review', 'data', ' ', 'receiv', 'custom', 'feedback', 'survey', 'data', 'past', 'year ', 'perform', 'sentiment', ' positive ', 'neg', ' ', 'neutral ', 'time', 'seri', 'analysi', 'custom', 'comment', '4', 'categories ', ' ', 'creat', 'heat', 'map', 'term', 'survey', 'categori', 'base', 'frequenc', 'word', ' ', 'extract', 'posit', 'neg', 'word', 'survey', 'categori', 'plot', 'word', 'cloud ', ' ', 'creat', 'custom', 'tableau', 'dashboard', 'effect', 'report', 'visualizations ', 'chatbot', ' ', 'develop', 'user', 'friendli', 'chatbot', 'product', 'handl', 'simpl', 'question', 'hour', 'operation ', 'reserv', 'option', 'on ', ' ', 'thi', 'chat', 'bot', 'serv', 'entir', 'product', 'relat', 'questions ', 'give', 'overview', 'tool', 'qa', 'platform', 'recommend', 'respons', 'user', 'question', 'build', 'chain', 'relev', 'answer ', ' ', 'thi', 'intellig', 'build', 'pipelin', 'question', 'user', 'requir', 'ask', 'relev', ' recommend', 'questions ', 'tool', ' ', 'technologies ', 'python ', 'natur', 'languag', 'processing ', 'nltk ', 'spacy ', 'topic', 'modelling ', 'sentiment', 'analysis ', 'word', 'embedding ', 'scikit learn ', 'javascript jquery ', 'sqlserver', 'inform', 'govern', 'organ', 'inform', 'decis', 'inform', 'store ', 'the', 'integr', 'inform', 'govern', 'portfolio', 'synthes', 'intellig', 'unstructur', 'data', 'sourc', 'facilit', 'action', 'ensur', 'organ', 'best', 'posit', 'counter', 'inform', 'risk ', ' ', 'scan', 'data', 'multipl', 'sourc', 'format', 'pars', 'differ', 'file', 'formats ', 'extract', 'meta', 'data', 'information ', 'push', 'result', 'index', 'elast', 'search', 'creat', 'customized ', 'interact', 'dashboard', 'kibana ', ' ', 'preform', 'rot', 'analysi', 'data', 'inform', 'data', 'help', 'identifi', 'content', 'redundant ', 'outdated ', 'trivial ', ' ', 'preform', 'full text', 'search', 'analysi', 'elast', 'search', 'predefin', 'method', 'tag', ' pii ', 'person', 'identifi', 'inform', ' social', 'secur', 'numbers ', 'addresses ', 'names ', 'etc ', 'frequent', 'target', 'cyber attacks ', 'tool', ' ', 'technologies ', 'python ', 'flask ', 'elast', 'search ', 'kibana', 'fraud', 'analyt', 'platform', 'fraud', 'analyt', 'investig', 'platform', 'review', 'red', 'flag', 'cases ', 'fap', 'fraud', 'analyt', 'investig', 'platform', 'inbuilt', 'case', 'manag', 'suit', 'analyt', 'erp', 'systems ', ' ', 'it', 'client', 'interrog', 'account', 'system', 'identifi', 'anomali', 'indic', 'fraud', 'run', 'advanc', 'analyt', 'tool', ' ', 'technologies ', 'html ', 'javascript ', 'sqlserver ', 'jquery ', 'css ', 'bootstrap ', 'node js ', 'd3 js ', 'dc j']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "resume_raw = pd.read_csv('UpdatedResumeDataSet.csv')\n",
    "resume_list = []\n",
    "\n",
    "for resume in resume_raw['Resume']:\n",
    "    resume_list.append(resume)\n",
    "    \n",
    "print(len(resume_list))\n",
    "resume_list_raw = resume_list\n",
    "\n",
    "resume_list = [remove_non_ascii(i) for i in resume_list]\n",
    "resume_list = [remove_stopwords(i).split() for i in resume_list]\n",
    "resume_list = [spl_chars_removal(i) for i in resume_list]\n",
    "resume_list_stemmed = [sentence_stemmer(i) for i in resume_list]\n",
    "    \n",
    "print(resume_list_stemmed[0])\n",
    "with open('resume_list_stemmed.pickle', 'wb') as handle:\n",
    "    pickle.dump(resume_list_stemmed, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c0b96f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------Resume-----------------------\n",
      "Education Details \n",
      " BE Computer Science Mumbai, Maharashtra Mumbai University\n",
      " HSC  Mumbai, Maharashtra Maharashtra State Board\n",
      " SSC  Mumbai, Maharashtra Maharashtra State Board\n",
      "Business Analyst \n",
      "\n",
      "Business Analyst - Fino Payments Bank\n",
      "Skill Details \n",
      "Company Details \n",
      "company - Fino Payments Bank\n",
      "description - Key Role   In-depth requirement and input gathering\n",
      "Responsibilities and Achievements:\n",
      "â¦ Conducted in-depth requirement and input gathering from all concerned stakeholders [Business SMEs, Technical Architect and Business Architect] to create artifacts like Business Requirement Document (BRD) to arrive at functional requirements for development team\n",
      "â¦ Created Functional Specification Document (FSD) highlighting the technical implementation and the use cases\n",
      "â¦ Led the Merchant Commission Module project from end-to-end and co-ordinated for CUG and Live\n",
      "â¦ Designed the Account Opening Process flow end-to-end during the time when bank was going Live.\n",
      "â¦ SPOC for all the configurations (both account level and customer level) in production.\n",
      "â¦ Led the Cash Controlling Processes for the field users as per the requirement from the business team.\n",
      "â¦ Design and build proof of concepts to validate the viability of alternate approaches and determine optimum choice\n",
      "â¦ Involved in Process Design for development of the products\n",
      "â¦ Performed Functional Testing of the entire system and provided support during UAT by preparing UAT test cases, performing UAT tests to onboard new processes as BAU\n",
      "â¦ Worked with the development teams in arriving at detailed techno-functional specifications, participate in Feasibility\n",
      "Analysis\n",
      "â¦ Conducting twice a week meetings with the vendor to discuss the status of CRs and to resolve technical queries\n",
      "company - Fino Paytech Pvt. Ltd\n",
      "description - Key Role   Requirement gathering, Development, Testing\n",
      "Responsibilities and Achievements:\n",
      "â¦ Requirement gathering, preparation of traceability matrix, preparation and execution of use cases, developing of test plans based on requirements for Airtel Zambia National Partner Project\n",
      "â¦ Led the employee profile creation, maintenance of employee details in the database: Preparation of work flow, end-to-end development and testing of the module\n",
      "â¦ Designed the work flow process of the CAPA (Corrective Action Preventive Analysis) module to maintain the audit findings raised by the internal audit team\n",
      "â¦ Designed the Expense Management module and automated it for end-to-end in-house expense flow\n",
      "â¦ Designed the PMO tool Parivartan used for tracking the projects end-to-end\n",
      "---------------------JD-----------------------\n",
      "Business Function Group Technology and Operations (T&O) enables and empowers the bank with an efficient, nimble and resilient infrastructure through a strategic focus on productivity, quality & control, technology, people capability and innovation. In Group T&O, we manage the majority of the Bank's operational processes and inspire to delight our business partners through our multiple banking delivery channels. Responsibilities Job Purpose To plan, participate and support project & change management of key IBGO programs across the key markets of the Bank. Coordinate and work closely with key stakeholders GTS, Technology, country T&O teams to gather requirements, build knowledge base of country processes, support stakeholders with adequate information gathering and analysis Contribute through supporting the Regional Cash agenda in all the key projects including e2e digitization. Key Accountabilities Support various IBGO projects through participation as core member where required. Regional Cash Subject Matter Expert on Cash related products like Payments, Receivables, Digital Channels, Liquidity management products Expert on cash management products like Payments, Receivables, Digital Channels and Liquidity management Liaise with stakeholders e.g. T&O teams across locations to gather requirements and document user stories Perform end to end UAT i.e. Plan UAT, document test scenarios, document and execute test cases Familiar with change management lifecycle and agile methodology Provide timely updates and status reports on progress of projects to all key stakeholders; escalate issues in a timely manner Support timely generation of Management Information, process workflows, data analysis Job Duties Be a core member of the IBG Ops projects from inception, planning, information gathering and implementation. Be a Core SME/Expert on Cash related products like Payments, Receivables, Digital Channels and Liquidity management and support the Regional Operations and business group for Change implementation Liaise with stakeholders e.g. T&O teams across locations to gather requirements and document user stories Perform end to end UAT i.e. Plan UAT, document test scenarios, document and execute test cases Familiar with change management lifecycle and agile methodology Establish a communication schedule to update sponsors, stakeholders, etc. on the progress of the projects. Facilitate meetings and interviews with process owners in gathering business requirements and communicating to the technology team. Support opportunities for process improvement and develop action plans and appropriate success measures. Requirements Bachelor's Degree from a recognized university At least 2-3 years of experience (preferred Subject Matter Expert) in managing Cash & Payment related projects like Payments, Receivables, Digital Channels and Liquidity management preferably in a large, global financial institution at a Regional Level Familiar with change management lifecycle and agile methodology Ability to work independently to gather requirements, prepare project plan, communicate to stakeholders Ability to perform end to end UAT i.e. Plan UAT, document test scenarios, document and execute test cases Strong influencing and negotiation skills along with excellent interpersonal and communication skills; strong verbal, written and presentation skills to key stakeholders within the organization Good insight in the latest digital technologies including Agile, data analytics, AI, API, Cloud computing, Mobile Technology Self-starter, with tenacity to succeed and passionate about digital automation Willing to challenge the status quo to drive better outcomes Ability to problem solve, creative and think out-of-the-box Knowledge of Transaction Banking Cash products is preferred Core Competencies Strong communication and written skills. Leadership skills Interpersonal skills Display strong initiative and drive Have good experience in using latest technologies including Microsoft Office 365 products, data analytics tools, Agile project management is an advantage. Apply Now We offer a competitive salary and benefits package and the professional advantages of a dynamic environment that supports your development and recognises your achievements.\n"
     ]
    }
   ],
   "source": [
    "tokenized_corpus = job_desc_docs_stemmed\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "idx = 403 # change this number to play around\n",
    "# i will make a proper list later\n",
    "tokenized_query = resume_list_stemmed[idx]\n",
    "print(\"---------------------Resume-----------------------\")\n",
    "print(resume_list_raw[idx])\n",
    "print(\"---------------------JD-----------------------\")\n",
    "\n",
    "doc_scores = bm25.get_top_n(tokenized_query, job_desc_docs_raw, n=5)\n",
    "print(doc_scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad15c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
